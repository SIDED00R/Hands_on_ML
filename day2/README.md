머신러닝의 주요 도전 과제
-나쁜 데이터
충분하지 않은 양의 훈련 데이터 : 알고리즘이 잘 작동하려면 간단한 문제에서도 수천개에서 복잡한 경우 수백만개의 데이터가 필요하다.
데표성 없는 훈련 데이터 : 샘플링 잡음이 생길 경우 대표성을 띄지 못하는 데이터가 들어가 샘플링이 편향되어 좋지 못한 결론이 나올 수 있다
낮은 품질의 데이터 : 훈련데이터가 에러, 이상치, 잡은으로 가득한 경우 이때는 데이터 정제에 시간을 들여서 사용해야한다
관련없는 특성: 가지고 있는 특성중에 훈련에 유용한 특성을 선택하고 특성끼리 결합하여 더 유용한 특성을 만들어 사용해아한다

-나쁜 알고리즘
훈련 데이터의 과대적합: 모델이 훈련 데이터에는 너무 잘 맞지만 일반성이 떨어지는 것, 이는 주로 데이터의 잡음의 양에 비해 모델이 너무 복잡할 때 발생한다. 따라서 파라미터수가 적은 모델을 사용하거나. 특성의 수를 줄이거나, 모델에 규제를 가하거나, 데이터 수를 늘리거나, 데이터의 노이즈를 제거하여 일반적인 경우에 더 맞게 하는 것을 사용하면 된다.
규제를 하는 경우 규제의 양은 하이퍼파라미터가 결정한다. 이는 학습 알고리즘의 파라미터이기 때문에 학습 알고리즘으로부터 영향을 받지 않고 훈련전에 미리 지정되며 훈련동안 계속 상수로 남게 된다.
이때 규제가 너무 큰 경우 과대적합은 피할지언정 좋은 모델이 안나오고 규제가 작으면 과대적합할 수도 있으므로 잘 선택해야한다.
훈련데이터의 과소적합: 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지못하는 경우 이 경우는 위와 반대로 파라미터가 더 많은 모델을 쓰거나, 알고리즘에 특성을 좋은것으로 바꾸거나 모델의 규제를 줄이는 방법을 사용한다


테스트와 검증
테스트 세트를 이용하여 검증을 하는 경우 실제 서비스 사용시 오차율이 큰 경우가 있다. 이는 훈련을 하면서 테스트세트에 최적화된 모델이 만들어 졌기 때문이다.
이러한 문제를 막기 위해서 대표적으로 홀드아웃 검증이라는 것을 사용할 수 있다. 
홀드아웃 검증 : 훈련 세트의 일부를 검증 세트로 떼어내어 여러 후보 모델을 평가하고 가장 좋은 하나를 택하는 방법이다.
이 과정이 끝나면 다시 검증 세트를 포함시켜 전체 훈련 세트에서 다시 훈련하여 최종 모델을 만들고 이를 테스트 세트에 평가하여 일반화 오차를 측정하는 것이다.
다만 검증세트를 너무 작게 고를경우 모델의 평가가 부정확해지고 검증세트가 너무 클경우 남은 훈련세트가 너무 작아져서 잘못된 모델이 만들어질 경우가 있다.
이를 해결하기 위해서 교차검을을 사용하는데, 이는 작은 검증세트를 여러 개 사용해아ㅕ 반복적으로 교차 검증을 수행해 검증세트마다 나머지 데이터에서 훈련한 모델을 해당 검증세트에서 평가하는 것이다.
이에 단점은 검증세트를 훈련세트를 n등분한다했을 때 n배의 시간이 걸려 세트수가 많을수록 걸리는 시간이 배로 늘어나는것이다

실제 데이터로 작업해보기
캘리포니아 주택가격 : 캘리포니아 인구조사 데이터를 사용해 캘리포니아의 주택 가격 모델을 만들자
데이터 : 블록 그룹마다 인구, 중간소득, 중간주택가격 …
목표: 다른 측정 데이터가 주어졌을 때 그 구역의 중간주택가격을 예측
레이블된 훈련 샘플이 있으므로 지도학습
데이터에 따른 값을 구하는 것이므로 회귀문제
데이터가 실시간으로 빠르게 변하는 것이 아니라 주어진것이므로 오프라인인 배치학습이다

성능지표는 회귀문제의 경우 대표적인 지표인 평균제곱근오차를 사용한다
다만 이상치가 많은 경우 평균 절대 오차를 사용하기도 한다
 
