## 대규모 텐서플로우 모델 훈련과 배포

모델을 만든 후에는 실제 제품에 장착해야한다.

시스템에 라이브 데이터 모델을 적용해야 하는 경우 모델을 웹 서비스로 만들어야한다.

이는 시간이 지나면 새로운 데이터에 모델을 정기적으로 다시 훈련해야하고, 업데이트 된 버전을 계속 반영해줘야한다.

만약 제품이 성공적이면 많은 QPS를 받게되어 서비스가 부하가 크게 생기게 되고 이를 견디기 위해 규모를 확장해야한다.

### 텐서플로우 모델 서빙

시스템이 커지게되면 모델을 서비스로 감싸는 것이 바람직하다

이는 모든 소프트웨어 구성 요소가 동일한 모델 버전을 사용하게 하여 테스트와 개발등을 단순화 한다.

텐서플로우 모델 서빙은 텐서플로우에서 제공하는 오픈 소스 모델 배포 플랫폼이다.

이 도구는 머신 러닝 모델을 서비스로 배포하고 관리하는 데 사용되는데, 모델 서빙은 모델을 사용할 수 있는 API를 제공하며, 클라이언트 응용 프로그램이 모델에 데이터를 보내고 예측을 받을 수 있도록 도와준다.

### 모바일 또는 임베디드 장치에 모델 배포하기

모바일이나 임베디드 장치에 모델을 배포할 때 모델이 크면 다운로드 하는데 시간이 오래걸리고, 너무 많은 RAM과 CPU를 사용하게 된다.

따라서 각각의 환경에 맞는 효율적이고 경량인 모델이 필요하다.

경량인 모델의 목표는 다운로드 시간과 RAM사용량을 줄이기 위해 모델의 크기를 줄이고, 응답속도, 베터리 사용량, 발열을 줄이기 위해 예측에 필요한 계산량 줄이고, 모델을 특정 장치의 제약조건에 맞추는 것이다.

TFLite 는 FlatBuffer기반의 경량 포맷으로 압축하는데 어떤 전처리 없이 바로 RAM으로 로드되어 로드에 걸리는 시간과 메모리 사용량을 줄인다.

모델의 크기를 줄이는 다른 방법은 더 작은 비트 길이를 사용하는 것이다.

만약 32비트 대신 16비트를 사용하면 정확도를 조금 읽는 대신 모델의 크기가 2배로 줄어든다.

또한 훈련 속도가 빨라지고 GPU RAM사용량이 반으로 줄어든다.

TFLite는 모델의 가중치를 8비트 정수로 압축하여 4배나 크기가 줄어들게 된다.

이렇게 압축을 하는 간단한 방법은 훈련 후 양자화를 하는건데 가장 큰 절댓값 가중치를 찾고 고정 소수점 범위로 매핑하는 것이다.

하지만 실행할 때는 양자화된 가중치를 다시 부동소수로 바꿔야하는데 복원할 때 약간의 손실이 발생하는 문제가 있다.

### 다중 장치에서 병렬 실행

텐서플로우에서 TF함수가 실행될 때 먼저 그래프를 분석하여 평가해야할 연산의 목록을 찾고, 각 연산이 다른 연산에 얼마나 많이 의존하는지 카운트하다.

그 다음 의존성이 없는 연산을 연산이 할당된 장치의 평가 큐에 추가하고 하나의 연산이 평가되면 그 연산에 의존하는 다른 모든 연산의 의존성 카운터를 감소시킨다. 

그리고 어떤 연산의 의존성 카운터가 0이되면 장치의 평가큐에 추가하는 방식으로 동작한다.

### 다중 장치에서 모델 훈련하기

여러 장치에서 하나의 모델을 훈련하는 방법은 두 가지가 있는데 하나는 모델을 여러 장치에 분할하는 모델 병렬화가 있고, 다른 하나는 모델을 각 장치에 복사하고 복사본을 데이터 일부분에서 훈련하는 데이터 병렬화가 있다.

- 모델 병렬화

  신경망 하나를 장치 여러 개에서 실행하려면 먼저 모델을 여러 부분으로 나누어 각 부분을 다른 장치에서 실행해야 한다.

  이는 매우 어렵고 신경망 모델의 구조에 매우 의존적이다.

  직관적으로 생각했을 때 모델의 각 층을 다른 장치에 배치하는 방식을 사용할 수 있지만, 기본적으로 이전층의 출력을 기다려야하기 때문에 큰 의미가 없다.

  대신 모델을 수직으로 분할하면 조금 상황이 나을 수 있는데 다음 층이 이전층의 양쪽의 출력 모두를 필요로 하기 때문에 장치간 통신이 매우 많이 발생한다.

  이때 장치간 통신은 매우 느려 병렬계산의 이점이 없게 된다.

  만약 합성곱 신경망과 같이 아래층의 부분적으로만 연결된 층을 가진다면 효율적으로 모델을 분산하기 좋다.

  즉, 모델 병렬화는 일부 신경망의 실행과 훈련 속도를 높일 수 있지만 전부는 아니고 대부분 같은 머신의 장치끼리 통신하게 하는 등 특별한 조정과 튜닝이 필요하다.

- 데이터 병렬화

  각 장치에 모델을 복제해서 각각 다른 미니배치를 사용해 모든 모델이 동시에 훈련 스텝을 실행실행하는 것이다.

  복제 모델에서 계산된 그레디언트 평균을 하고 그 결과를 사용해 모델 파라미터를 업데이트를 한다.

   - 미러드 전략을 사용한 데이터 병렬화

     가장 간단한 방법은 모델 파라미터를 모든 GPU에 완전히 똑같이 복사하고 항상 모든 GPU에 동일한 파라미터 업데이트를 적용하는 방식이다.

     이 방식을 사용할 때 어려운 부분은 모든 GPU에서 얻은 그레디언트 평균을 효울적으로 계산하고 그 결과를 모든 GPU에 배포하는 것이다.
     
   - 중앙 집중적인 파라미터를 사용한 데이터 병렬화
 
     계산을 수행하는 GPU장치 밖에 모델 파라미터를 저장하여 장치 밖에서 파라미터를 보관하고 업데이트한다.

     이 방식을 사용하면 동기 업데이트와 비동기 업데이트를 모두 사용할 수 있다.

      - 동기 업데이트

        모든 그디언트가 준비될 때 까지 그레디언트 수집기가 기다린 다음 평균 그레디언트를 계산해서 모델 파라미터를 업데이트 할 옵티마이저에게 전달하는 방식이다.

        따라서 한 모델이 계산을 마치더라도 다음 미니배치를 처리하기 전에 파라미터가 업데이트 될 때까지 기다려야한다.
        
      - 비동기 업데이트

        복제 모델이 그레디언트 계산을 끝낼 때 마다 즉시 모델 파라미터를 업데이트한다.

        다만 이러한 방식은 전혀 효과가 없는데 계산된 그레디언트가 정확한 방향을 가리킬 것이라는 보장이 없기 때문이다.

        이는 낡은 그레디언트라고 하는데 수렴을 느리게 하고 잡음과 흔들림을 발생시키거나 발산하게 만든다.

  데이터 병렬화는 매 훈련 스텝이 시작될 때 파라미터 서버에서 복제된 모델로 모델 파라미터를 전송해야한다.
  
  그리고 훈련이 끝날 때 그레디언트를 반대 방향으로 전달한다.
  
  이때 GPU RAM의 입력과 출력으로 데이터를 옯기는데 드는 시간이 계산 부하를 분할해서 얻는 속도보다 커지게되어 많은 GPU를 추가하면 대역폭을 더 포화시키고 훈련을 느리게 만들 수 있다.
