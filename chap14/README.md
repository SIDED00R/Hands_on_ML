## 합성곱 신경망(CNN)

- CNN의 발전 과정
  
  합성곱 신경망은 시각 피질 안의 많은 뉴런이 작은 국부수용장을 가진다는 개념에서 출발하였다.
  
  특히 시각 피질 안의 많은 뉴런이 작은 국부 수용장을 가진다는 것을 확인 하였는데 이는 뉴런들이 시야의 일부 범위 안에 있는 시각 자극에만 반응한다는 뜻이다.

  뉴런의 수용장은 서로 겹쳐질수 있어 합치면 전체 시야를 감싸게 된다.
  
  따라서 고수준의 뉴런이 이웃한 저수준의 뉴런의 출력에 기반한다는 아이디어를 얻게 되었고 이를 발전시켜 점차 합성곱 신경망으로 진화하였다.

CNN에서 가장 중요한 구성요소는 합성곱 층이다. 첫 번째 합성곱 층의 뉴런은 입력 이미지의 모든 픽셀에 연결되는 것이 아니라 합성곱 층 뉴런의 수용장 안에 있는 픽셀에만 연결된다.

두번째 합성곱 층에 있는 각 뉴런은 첫번째 층의 작은 사각 영역 안에 위치한 뉴런에 연결되는데 이런 구조는 네트워크가 첫번째 은닉층에서 작은 저수준 특성에 집중하고 , 그 다음 은닉층에서는 더 큰 고수준 특성을 조합해나가도록 도와준다.

- 패딩

  CNN 레이어를 적용하면 출력 크기가 입력 크기보다 작아지게 된다.

  만약 여러 개의 합성곱 레이어를 쌓은 경우, 출력 크기가 지나치게 작아져 정보의 손실을 초래할 수 있다.

  따라서 입력 주변에 값이(일반적으로 0) 채워진 패딩을 추가하여 출력 크기를 보존하거나 늘릴 수 있게 하면 중요한 정보의 손실을 방지하고 신경망이 입력의 모든 부분을 고려할 수 있게 된다.

  그리고 합성곱 연산을 수행하면 입력 이미지의 중심에 위치한 픽셀은 더 많은 합성곱 필터와 상호 작용하게 되지만 상대적으로 가장자리에 위치한 픽셀은 중앙에 위치한 픽셀에 비해 덜 다른 픽셀과 상호 작용한다.

  이로 인해 경계 부분에 있는 중요한 특징이 손실될 수 있어 패딩을 사용하여 이미지의 가장자리나 경계 부분에 있는 중요한 특징을 잃지 않도록 하기 위해 패딩을 사용한다.
  
- 스트라이드

  스트라이드는 입력 데이터를 어떤 간격으로 슬라이딩할지 결정하는 매개변수로 한 수용장과 다음 수용장 사이 간격을 의미한다.

  스트라이드를 크게하면 입력층을 훨씬 작은 층에 연결하게 할 수 있다.

 - 필터(합성곱 커널)

   필터는 데이터 에서 필터를 가장 크게 활성화 시키는 이미지 영역을 강조하는 하나의 특성 맵을 만든다.

   실제 합성곱층은 여러가지 필터를 가지고 필터마다 하나의 특성맵을 출력하여 3d로 표현한다.

   합성곱 층l에 있는 k특성 맵의 i행 j열에 위치한 뉴런은 이전l-1층에 있는 모든 특성맵의 $i \times s_h$ 에서 $i \times s_h + f_h - 1$까지의 행과 $j \times s_w$에서 $j \times s_w + f_w -1$까지의 열에 있는 뉴런의 출력에 연결된다.<br>
   ($s_h, s_w$는 각각 스트라이드의 수직 값과 수평 값)

합성곱 층에 있는 뉴런의 출력 계산 식

$$
z_{i,j,k} = b_k + \sum\limits_{u = 0}^{f_h - 1} \sum\limits_{v = 0}^{f_w - 1} \sum\limits_{k' = 0}^{f_{n'} - 1} x_{i', j', k'} \times w_{u, v, k', k}
\quad \text{with }
\begin{cases}
i' = i \times s_h + u \\
j' = j \times s_w + v
\end{cases}
$$

$z_{i,j,k}$ : 합성곱 층의 k특성 맵에서 i행 j열에 위치한 뉴런의 출력

$s_h, s_w, f_h, f_w, f_{n'}$ : 각각 스트라이드의 수직 값과 수평 값, 수용장의 높이와 너비 그리고 이전 층에 있는 특성맵의 수

$x_{i', j', k'}$ : l-1 층의 i'행, j'열, k'특성 맵의 출력

$b_k$ : k특성 맵의 편향

CNN의 문제는 훈련하는동안에 역전파 알고리즘이 역방향 계산을 할 때 정방향에서 계산했던 모든 중간값을 필요로 하기 때문에 합성곱 층에 많은 양의 RAM을 필요로 한다는 점이다.

예를들어 5X5필터에 스트라이드1과 패딩을 사용해 150X100 크기의 특성맵 200개를 만드는 합성곱 층에서 입력이 RGB이미지로 채널이 3개이면 파라미터수는 (5 X 5 X 3 + 1(편향)) X 200 = 15,200이다.

여기에 특성 맵 마다 100 X 150개의 뉴런이 있으므로 대략 228,000,000개의 실수의 곱샘을 해야한다.

만약 완전 연결층을 사용해 연결한다면 150X100X3 입력에 연결된 150X100뉴런으로 이뤄진 완전 연결층은 $150^2 \times 100^2 \times 3 = 675,000,000$개의 파라미터를 가진다.

따라서 매우 적은 수의 파라미터를 가지지만 그래도 계산량이 매우 많다.

여기에 특성 맵이 32비트 부동 소수점으로 표현되고 매치가 100개인 샘플로 이뤄져 있다면 200 X 150 X 100 X 32 X 100 = 1.2GB에 해당하는 램을 사용하게 된다.

### 풀링층

풀링층은 계산량과 메모리 사용량, 파라미터 수를 줄이기 위해 입력 이미지의 부표본(축소본)을 만드는 것이다.

풀링뉴런은 가중치가 없기 때문에 최대나 평균 같은 합산 함수를 사용해 입력값을 더하는 것이 전부이다.

풀링은 입력 데이터의 작은 이동, 회전, 크기 변화 또는 기타 변형에 대해 작은 변화에도 일정수준의 불변성을 만들어준다.

다만 풀링은 매우 파괴적이여서 입력값을 많이 잃게된다.

전역 평균 풀링층은 주로 신경망 구조의 마지막에서 보게 되는데 이는 각 특성 맵의 평균을 계산하는 것으로 각 샘플의 특성맵 마다 하나의 숫자를 출력한다는 뜻이다.

이는 매우 파괴적인 연산이지만 출력층에는 유용할 수 있다.

### CNN 구조

전형적인 CNN구조는 합성곱 층 몇 개를 쌓고 풀링층을 쌓고 합성곱 층을 몇 개 더 쌓고 다시 풀링층을 쌓는식으로 되어있다.

따라서 네트워크를 통과할수록 이미지는 점점 작아지지만 합성곱 층 때문에 일반적으로 더 많은 특성 맵을 가져 깊어진다.

- AlexNet

  최초로 합성곱 층 위에 풀링층을 쌓지않고 바로 합성곱 층 끼리 쌓았다.

  그리고 과대 적합을 줄이기 위해서 두 가지 규제 기법을 사용하였는데 먼저 드롭아웃을 50% 비율로 적용하였고, 이미지를 랜덤하게 여러 간격으로 이동하거나 수평로 뒤집고 조명을 바꾸는 식으로 데이터 증대를 수행하였다.

  데이터 증대는 진짜 같은 훈련 샘플을 인공적으로 생성하여 훈련 세트의 크기를 늘리는 방식으로 과대적합을 줄이게 되어 규제 기법으로 사용할 수 있다.

  생성된 샘플의 조건은 진짜에 가까워 훈련세트에서 임의로 뽑았을 때 구분할 수 없어야한다.

  데이터를 수평으로 뒤집고 기울이는 과정을 통해서 물체의 위치 방향 크기변화에 덜 민감해지게 된다.

  또한 AlexNet은 RelU단계 후에 바로 IRN이라는 경쟁적인 정규화 단계를 사용하였는데 이는 가장 강하게 활성화 된 뉴런이 다른 특성맵에 있는 같은 위치의 뉴런을 억제한다.

  따라서 각각의 특성맵이 다른것과 구분되게 하고, 더 넓은 시각에서 특징을 탐색하도록 만들어 일반화 성능을 높인다.

$$
b_i = a_i  \left(k + \alpha \sum\limits_{j=j_\text{low}}^{j_\text{high}}{{a_j}^2} \right)^{-\beta} \quad \text{with }
\begin{cases}
  j_\text{high} = \min\left(i + \dfrac{r}{2}, f_n-1\right) \\
  j_\text{low} = \max\left(0, i - \dfrac{r}{2}\right)
\end{cases}
$$

$b_i$ : i특성맵, u행, v열에 위치한 뉴런의 정규화된 출력

$a_i$ : ReLU단계를 지나고 정규화 단계를 거치기 전 뉴런의 활성화 값

 - GoogLeNet

   인셉션 모듈이라는 서브 네트워크를 가지고 있어 이전의 구조보다 훨씬 효과적으로 파라미퍼를 사용한다.

   인셉션 모듈은 처음에 입력신호가 복사되어 네 개의 다른 층에 주입된다.

   모든 합성곱 층은 ReLU 활성화 함수를 사용한다.

   두 번째 합성곱 층은 서로 다른 커널의 크기를 사용해 다양한 크기의 패턴을 감지한다.

   이때 커널중에서 1 X 1 커널을 사용하는데 이는 한번에 하나의 픽셀만 처리하기 때문에 의미가 없는거처럼 보이지만 세 가지 장점이 있다.

   1. 고차원 특성 맵을 압축할 때 병목 층의 역할을 하여 낮은 차원의 특성 맵으로 압축이 가능하게 한다.
  
   2. 모델의 깊이가 더 증가하여 더 복잡한 패턴을 감지 할 수 있는 하나의 강력한 합성곱 층처럼 작동한다.
  
   3. ReLU와 같은 비선형 활성화 함수와 같이 사용되어 비선형성이 높아지는데 이는 모델이 더 복잡한 함수를 모델링 할 수 있게 하며 모델의 표현력을 높일 수 있게 된다.

 - VGGNet

   2개 또는 3개의 합성곱 층 뒤에 풀링층이 나오고 다시 2개 또는 3개의 합성곱층과 풀링층이 등장하는 식이다.

   마지막 밀집 네트워크는 2개의 은닉층과 출력층으로 이뤄진다.

 - ResNet

   잔차 네트워크를 사용해서 152층의 극도록 깊은 CNN을 사용하였다.

   일반적으로 깊은 신경망에서는 기울기 소실 또는 기울기 폭주 문제가 발생하기 쉬워 이로 인해 가중치가 적절하게 업데이트되지 않고, 학습이 어려진다.

   하지만 이런 깊은 네트워크를 ResNet은 스킵연결 이라는 요소로 문제없이 훈련시킬 수 있었다.

   - 스킵연결

     스킵연결은 어떤 층에 주입되는 신호가 상위층의 출력에도 더해지는 것이다.

     목적함수가 항등함수에 가까우면 훈련속도가 매우 빠른데 스킵연결을 추가하면 입력과 같은 값을 출력하기 때문에 학습 초기에는 항등함수를 모델링하게 되어 빠른 속도로 학습을 하게 된다.

     그리고 스킵연결을 많이 추가하면 일부층이 아직 학습되지 않더라도 네트워크는 훈련을 시작할 수 있다.

     그러면 스킵연결 덕분에 입력신호가 전체 네트워크에 손쉽게 영향을 미치게 된다.
   
   ResNet에서 특성맵의 수는 몇 개의 잔차 유닛마다 2배로 늘어나게 되고 높이와 너비는 절반이 된다.

   이러한 경우 입력과 출력의 크기가 다르기 때문에 바로 입력이 잔차유닛의 출력에 더해질 수 없다.

   이러한 문제를 해결하기 위해 스킵되는 입력값을 스트라이드가 2이고 출력 특성 맵의 수가 같은 1 X 1 합성곱 층으로 입력을 통과시킨다.

 - Xception

   이는 GoogLeNet과 ResNet의 아이디어를 합쳤지만, 인셉션모듈을 깊이별 분리 합성곱 층이라는 특별한 층으로 대체하였다.

   일반적인 합성곱 층이 공간상의 패턴과 채널사이 패턴을 동시에 잡기 위해서 필터를 사용하는데, 분리 합성곱 층은 공간패턴과 채널사이 패턴을분리하여 모델링할 수 있다고 가정한다.

   분리 합성곱 층은 두 개의 부분으로 구성되는데, 첫 번째는 하나의 공간 필터를 각 입력 특성맵에 적용하는 것이고, 두 번째는 1 X 1 필터를 사용해서 채널사이 패턴만 조사한다.
   
 - SENet

   인셉션 네트워크와 ResNet같은 기존 구조에 SE 블록이라는 작은 신경망을 추가하여 성능을 항상하였다.

   - SE 블록

     SE 블록은 3개의 층으로 구성되는데 전역 평균 풀링, relu활성화 함수를 사용하는 밀집 은닉층, 시그모이드 활성화 함수를 사용하는 밀집 출력층으로 구성된다.

     처음 전역 평균 풀링층이 각 특성맵에 대한 평균 활성화 값을 계산한다.

     그리고 다음 밀집 은닉층에서 압축이 발생하는데, 이 압축된 저차원 벡터는 특성 응답의 분포를 표현한다.

     이 병목층을 통해 SE블록이 특성 조합에 대한 일반적인 표현을 학습한다.

     마지막 출력층은 위의 결과를 받아 특성맵마다 0, 1사이의 하나의 숫자를 담은 보정된 벡터를 출력한다.

     그 다음 특성 맵마다 이 보정된 벡터를 곱해 관련없는 특성값을 낮추고 관련있는 특성값은 그대로유지한다.

     이는 데이터의 특정 요소가 다른 요소와 혼동이 될 경우 특성 맵 보정이 이러한 애매함을 해결하는게 도움이된다.
   
   SE 블록이 추가된 부분의 유닛의 출력을 공간 패턴은 신경쓰지 않고 깊이 차원에서 분석하여 어떤 특성이 동시에 가장 크게 활성화 하는지 학습한다.

### 객체 탐지

하나의 이미지에 여러 물체를 분류하고 위치를 추정하는 작업을 객체 탐지라고 한다.

주로 사용했던 방법은 물체를 분류하고 위치를 찾는 분류기를 훈련한 다음 이미지를 모두 훑어서 객체를 찾는 방식을 사용하였다.

이러한 방식은 매우 쉽지만, 조금씩 다른 위치에서 동일한 객체를 여러 번 감지하게되는 비효율적인 상황이 발생한다.

간단한 방법으로는 NMS방식으로 불필요한 바운딩 박스는 제거하여 이러한 비효율을 줄일 수 있다.

NMS방식은 합성 신경망에 다른 꽃이 존재하는지 확률을 추정하기 위해 존재여부출력을 추가한다.

그 후 일정 점수 이하의 존재여부는 임계값 이하는 모두 삭제한다. 

그리고  존재여부 점수가 가장 높은 바운딩 박스를 찾고, 이 박스와 많이 중첩된 다른 바운딩 박스를 모두 제거한다. 

왜냐하면 같은 물체 위에 있는 다른 바운딩 박스는 최대댓값을 가진 박스와 많이 중복되기 때문이다.

NMS방식과 같은 간단한 객체 탐지 방식은 잘 작동하지만 기본적으로 CNN을 여러 번 실행시켜야 하기 때문에 많이 느리다.

# 완전 합성곱 신경망

 - YOLO

   요로는 각 격자 셋마다 5개의 바운딩 박스를 출력한다. 바운딩 박스마다 하나의 존재여부 점수가 부여

   신경망을 훈련하기 전에 욜로는 앵커박스라  불리는 5개의 대표 바운딩 박스 크기를 찾는다.

   이를 위해 k-mean알고리즘을 훈련 세트 바운딩 박스의 높이와 넓이에 적용한다.


# 시맨틱 분할

각 픽셀은 픽셀이 속한 객체의 클래스로 분류된다.

클래스가 같은 물체는 구별되지 핞는다.





