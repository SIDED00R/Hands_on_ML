## 모델 훈련

### 선형 회귀

입력특성의 가중치 합과 편향을 더해 예측을 만든다
$\hat y = \Theta_0 + \Theta_1x_1 + \Theta_2x_2 + … + \Theta_nx_n$

여기서 $\hat y$는 예측값, n의 특성의 수 $x_i$는 i번째 특성값이고 $\Theta_j$는 j번때 모델 파라미터이다

백터형태 : $\hat y = \Theta \cdot X$

여기서 $X = [x_0, x_1, x_2 … x_n]^T$ 단, $(x_0 = 1)$

회귀에 가장 널리 사용되는 비용함수는 평균제곱오차(RMSE)이다.

$$(MSE) = {1 \over m} \sum_{i=1}^m ( \Theta x^{(i)} – y^{(i)} )^2 ,\quad (RMSE) = \sqrt {(MSE)}$$

### 비용함수를 구하는 방법

1.	해석적인 방법 : 수학 공식을 이용해서 바로 결과값 구하기

대표적으로 정규 방정식으로 구하는 방법이 있다.

정규방정식 : $\hat \Theta = (X^T X)^{-1} X^T y$

단, 정규방정식은 $(n + 1)^2$ 크기의 $X^T X$ 의 역행렬을 구해야 하는 과정이 존재한다. <br>
따라서 이는 계산 복잡도가 O($n^{2.4}$) ~ O($n^3$)이므로 매우 시간이 오래 걸리게 된다.

2.	경사하강법 : 비용함수를 최소화 하기 위해 반복해서 파라미터 조정해가는 것

파라미터 벡터의 세타에 대해 비용함수의 현재 그레디언트를 계산하고, 해당 값이 감소하는 방향으로 진행시켜 그레디언트가 0이 되게끔 하는 방식이다.

경사 하강법에서 중요한 파라미터는 학습률로 스텝의 크기를 의미한다. 

만약 학습률이 너무 작다면 모델을 구하기 위해 많은 탐색을 해야하여 시간이 오래걸리고, 학습률이 너무 크다면 우리가 찾아야하는 값을 지나쳐 오히려 그레디언트가 더 커질수 있다.

적절한 학습률을 찾기 위해선 그리드 탐색을 해야한다.
이때 학습률이 너무 크거나 작은 경우에는 시간이 오래걸린 가능성이 있다.
따라서 반복 횟수를 설정하고, 이 횟수 내로 그레디언트 벡터가 작아져 허용오차안으로 들어오면 알고리즘을 중지하고, 횟수가 넘어가면 그대로 중지하여 다른 값을 테스트해봐야한다.

경사하강법의 문제점은 무작위 초기화 때문에 내가 수렴한 값이 지역 최솟값은 맞을지언정 전역최솟값이 아닐 수 있기 때문이다.

### 경사 하강법의 종류

-	배치 경사 하강법 : 매 경사 하강법 스텝에서 전체 훈련세트x에 대해 계산한다. 이는 매 스텝 전체 데이터를 사용하기 때문에 느리지만 특성 수에 민감하지 않아 수십만개의 특성에서 훈련싵키기 위해서는 훨신 더 좋다

- 확률적 경사 하강법: 매 스텝 한 개의 샘플을 무작위로 선택해 그레디언트를 계산하여 처리한다.<br>
  이는 매 스텝 한 개의 샘플만 계산을 하기 때문에 큰 훈련셋에도 훈련이 가능하고 시간이 적게 걸린다.
  
  다만, 이는 확률적이므로 배치 경사하강법보다 불안정하다.<br>
  즉, 알고리즘이 멈출 때 대체적으로 준수한 파라미터가 나오지만 이것이 최적의 값이 아닐 수도 있다.
  
  하지만 오히려 무작위성 때문에 지역최솟값에서 값이 수렴하는 것을 탈출시켜 전역최솟값을 찾게 할수도 있다.

  - 학습 스케줄
    
    초반에는 학습률을 크게하여 수렴 속도를 빠르게 하고, 점차 학습률을 줄여 수럼값에 더 정밀하게 수렴하게하는 학습 스케줄 방법도 있다.
    
    다만, 매 반복에서 학습률을 결정하는 함수로 학습률이 너무 빨리 줄어든다면 값이 지역 최솟값에 갇히거나 최솟값에 도달하기 전에 멈춰버릴수 있고, 학습률이 천천히 줄어들면 값이 최솟값 주위를 맴돌수 있다.

-	미니배치 경사 하강법 : 각 스텝에서 미니배치라고 부르는 임의의 작은 샘플 세트에 대해 그레디언트를 계산하는 것이다. 

### 다항 회귀

가지고 있는 데이터가 비선형 데이터일 경우 선형 모델로 학습하기 위해서는 각 특성의 거듭제곱을 새로운 특성으로 추가하고 이 확장된 특성을 포함한 데이터셋에 선형모델을 훈련시키는 것이다.

### 학습곡선

훈련셋과 검증셋의 모델성능을 훈련셋의 크기의 함수로 나타낸것이다. 

이는 단순히 훈련세트에서 크기가 다른 서브 세트를 만들어 모델을 여러 번 훈련시키면 된다.

훈련세트에 샘플이 적은 경우는 모델이 완벽하게 작동하지만, 세트에 샘플이 추가되면 될수록 데이터에 잡음도 있고, 비선형이기 때문에 모델이 데이터를 완벽하게 학습하는 것이 불가능하진다.

따라서 모델이 어느정도까지는 계속 오차가 상승하게 되다가 일정수준 이상이 되면 수렴하여 데이터가 추가되어도 오차가 크게 바뀌지 않는다.

검증세트의 경우는 초반에 훈련샘플이 적을때는 제대로 일반화되지 않아 오차가 초반에 매우 크지만, 샘플이 추가되면 될수록 모델이 학습되고 오차가 천천히 감소하게되어 훈련세트의 수렴값과 가까워지게 된다.

이때 수렴하는 값이 훈련세트와 검증세트 모두 큰 값으로 수렴하면 과소적합한 모델인것이다.

그리고, 훈련세트는 낮은값으로 수렴을 하였지만 검증세트는 높은값으로 수렴하여 둘 사이의 차이가 큰 경우는 모델이 과대적합 되었다고 볼 수 있다.

### 모델의 일반화 오차

-	편향 : 잘못된 학습 알고리즘의 가정으로 생기는 것이다

-	분산 : 훈련 데이터에 있는 작은 변동에 모델이 민감하게 반응하여 생기는 오차이다

-	줄일수 없는 오차 : 데이터 자체에 있는 잡음으로 오차를 줄이기 위해서는 데이터의 잡음을 제거하는 방법밖에 없다.

-	편향 분산 트레이드오프 : 일반적으로 모델의 복잡도가 늘어나면 분산이 늘어나고 편향이 줄어든다. 반대로 모델의 복잡도가 줄어들면 편향이 커지고 분산이 작아진다.

### 규제가 잇는 선형모델

과대적합을 감소시키는 좋은 방법은 모델에 규제를 하는것이다.

다항 회귀 모델의 경우 간단히 다항식의 차수를 줄이는 것이 규제가 될 수 있다.

선형회귀 모델에서는 모통 모델의 가중치를 제한함으로 규제를 가한다

1.	릿지 회귀: 규제항이 비용함수에 추가된다.
   
$$ J(\Theta) = MSE(\Theta) + \alpha {1 \over 2} { \sum_{i=1}^n \Theta_i^2} $$

이는 모델의 가중치가 가능한 작게 유지되려고 노력한다. Alpha는 모델을 얼마나 많이 규제할지 조절한다.

규제가 작으면 그냥 선형 회귀와 같아지고, 규제가 크면 모든 가중치가 거의 0에 가까워져 데이터의 평균을 지나는 수평선이 된다.

2.	라쏘 회귀 : 규제항이 비용함수에 추가된다.
   
$$ J(\Theta) = MSE(\Theta) + \alpha \sum_{i=1}^n |\Theta_i| $$

라쏘회귀는 덜 중요한 특성의 가중치를 제거하려고 하는 것이다.
즉, 라쏘회귀는 자동으로 특성을 선택하고 희소모델을 만든다

3.	엘라스틱넷 : 릿지와 라쏘 회귀를 절충한 모델이다.

$$ J(\Theta) = MSE(\Theta) +  r \alpha \sum_{i=1}^n |\Theta_i| + \alpha {{1 - r} \over 2} { \sum_{i=1}^n \Theta_i^2} $$

규제항은 둘을 더해서 사용하고 혼합정도는 혼합비율r을 조절해서 사용한다.

r = 0이면 릿지회귀와 같고, r = 1이면 라쏘회귀와 같게된다.

일반적으로 릿지회귀가 기본으로 사용된다.

특성의 개수가 적을 경우 가중치를 0으로 만드는게 더 좋기 때문에 라쏘회귀나 엘라스틱넷을 사용한다.

특성의 수가 데이터의 수보다 많거나 특성끼리 강하게 연관되어있는 경우 라쏘회귀보다는 엘라스틱넷이 더 좋다.<br>
왜냐하면 라쏘회귀는 샘플수보다 특성이 많을 경우 최대 샘플수만큼 특성을 선택하고, 특성이 강하게 연관된 경우 이들 중 임의의 특성만 선택해버리기 때문이다.

### 로지스틱 회귀

샘플이 특정 클래스에 속할 확률을 추정하는데 사용된다.

로지스틱은 입력 특성의 가중치 핪을 계산하고 편향을 더한다. 그리고 선형회귀처럼 값을 바로 출력하지 않고 결괏값인 로지스틱을 출력한다.

로지스틱은 0과 1의 사이 값을 출력하는 시그모이드 함수인데 $1 \over {1 + e^{-t}}$로 표기된다

그리고 값이 0.5 이상이면 1을 출력하고, 0.5 미만이면 0으로 출력하는 모델을 만든다.

### 로지스틱 회귀의 비용함수 (로그 손실)

훈련을 통해서 모델을 찾기 위해 비용함수를 설정해야한다.

따라서 y = 1인 양성 샘플에 대해서는 높은 확률 추정하고, y = 0인 음성샘플에 대해서는 낮은 확률 추정하는 모델을 로그 손실이라하고 다음과 같다.
$$J(\Theta) = - {1 \over m} \sum_{i=1}^n {y^{(i)} log(\hat p^{(i)}) + (1 - y^{(i)}) log(1 - \hat p^{(i)})}$$

### 소프트맥스 회귀

로지스틱 회귀 모델은 여러 개의 이진 분류기를 훈련시켜 연결하지 않고 직접 다중 클래스를 지원하도록 일반화 할 수 있는데 이를 소프트맥스 회귀라고 한다.

이는 샘플X가 주어지면 각 클래스K에 대한 점수를 계산하고 그 점수에 소프트맥스함수를 적용하여 각 클래스의 확률을 추정한다.

$$ 
(소프트맥스 함수) = \frac {e^{s_k(x)}}{ \sum {e^{s_k(x)}} } , \quad s_k(x) = (\Theta^{(k)})^T x
$$


