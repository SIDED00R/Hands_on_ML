## 머신러닝이란?

  - 일반적인 정의 : 명시적인 프로그래밍 없이 컴퓨터가 학습하는 능력을 갖추게 하는 연구 분야 (아서 새무얼 1959)

  - 공학적인 정의 : 어떤 작업T에 대한 컴퓨터 프로그램의 성능을 P로 측정했을 때 경험E로 인해 성능이 향상됐다면 이 컴퓨터 프로그램은 작업T와 성능 측정P에 대한 경험 E로 학습한것이다 (톰 미첼 1997)

시스템이 학습하는데 사용하는 샘플 -> 훈련 세트 (trainging set)

스팸 필터를 공학적인 정의에서 보면 T는 새로운 메일이 스팸인지 구분, E는 훈련 데이터, 성능측정P는 예를들어 정확히 분류된 메일의 비율과 같이 따로 정해야 한다.
그리고, 성능측정을 정확도라고 하여 분류작업에 자주 사용한다.

머신 러닝을 사용하는 이유 : 전통적인 프로그래밍 기법 사용시 문제가 어려우면 규칙이 점점 길고 복잡하여 유지보수가 힘들다 하지만 머신러닝을 기반으로 하면 패턴분석을 통해 비교적 간단히 처리 가능하다

## 머신러닝의 종류

### 지도학습과 비지도학습
 - 지도학습 : 훈련 데이터에 레이블이라는 원하는 답이 포함되어 있다.
대표적으로 분류(classification), 예측 변수(predictor variable)를 통해 target 의 수치를 예측하는 회귀 (regression)가 있다

 - 비지도 학습: 훈련 데이터에 레이블이 없는 데이터를 통해 학습하는 것이다.
대표적으로 군집(clustering), 시각화와 차원축소(visualization & dimensionality reduce), 연관 규칙 학습(association rule learning)이 있다

 - 준지도학습: 일부의 데이터만 레이블값을 가지고 있는 경우이다.
 일반적으로 데이터에 레이블을 다는 것은 일반적으로 시간과 비용이 많이 들기 때문에 레이블이 없거나 일부만 레이블을 가진 경우가 흔하다.
  
 - 강화학습: 학습하는 시스템을 에이전트라고 부르고 환경을 관찰해 행동을 실행하고 해당 결과에 따른 보상 또는 벌점을 받는다. 결과적으로 가장 큰 보상을 얻기 위해 정책policy라고 불리는 최상의 전략을 스스로 학습한다
대표적으로 알파고 같은 예시가 있다

### 배치학습과 온라인 학습
 - 배치학습: 가지고있는 모든 데이터를 사용하여 훈련한다. 따라서 많은 시간과 자원을 소모하여 주로 오프라인에서 수행된다. 그리고 시스템이 훈련되고 적용할때는 더 이상 학습 없이 실행이 된다.

 - 온라인학습: 데이터를 순차적으로 한 개씩 또는 미니배치를 이용해 시스템을 훈련한다. 이는 학습이 빠르고 비용이 적게드는 특징이 있다. <br>
  온라인 학습에 중요한 파라미터중 하나인 학습률은 변화하는 데이터에 얼마나 빠르게 적응하는것인가 이다.<br>
  학습률이 빠르면 데이터에 빠르게 적응하지만 이전 데이터가 금방 잊혀진다.<br>
  반대의 경우는 시스템의 관성이 커져 느리게 학습이 된다. 다만 이 경우는 새로운 데이터의 잡음이나 대표성이 없는 데이터에 덜 민감해지는 장점이 있다.<br>

### 사례기반 학습과 모델기반 학습
 - 사례기반: 시스템이 훈련 샘플을 기억하고 유사도 측정을 통해 새로운 데이터와 학습한 샘플을 비교하는 식으로 일반화한다.

 - 모델기반: 샘플 모델을 만들어 예측에 사용하고, 모델을 사용하기 전에 각각의 파라미터 값을 정해야하고 모델이 얼마나 좋은지 측정하는 효용함수utility function 또는 얼마나 나쁜지 측정하는 비용함수 cost function을 정의한다.

## 머신러닝의 주요 도전 과제

### 나쁜 데이터
 - 충분하지 않은 양의 훈련 데이터 : 알고리즘이 잘 작동하려면 간단한 문제이더라도 수천개의 데이터가 필요하고, 복잡한 경우 수백만개의 데이터가 필요하다.
  
 - 대표성 없는 훈련 데이터 : 샘플링 잡음이 생길 경우 대표성을 띄지 못하는 데이터가 들어가 샘플링이 편향되어 좋지 못한 결론이 나올 수 있다.
 
 - 낮은 품질의 데이터 : 훈련데이터가 에러, 이상치, 잡음으로 가득한 경우로 이때는 데이터 정제에 시간을 들여서 사용해야한다.
 
 - 관련없는 특성: 가지고 있는 특성중에서 훈련에 유용한 특성을 선택하고, 특성끼리 결합하여 더 유용한 특성을 만들어 사용해아한다.

### 나쁜 알고리즘
 - 훈련 데이터의 과대적합: 모델이 훈련 데이터에는 너무 잘 맞지만 일반성이 떨어지는 것으로, 이는 주로 데이터의 잡음의 양에 비해 모델이 너무 복잡할 때 발생한다. 따라서 파라미터수가 적은 모델을 사용하거나, 특성의 수를 줄이거나, 모델에 규제를 가하거나, 데이터 수를 늘리거나, 데이터의 노이즈를 제거하여 일반적인 경우에 더 맞게 하는 것을 사용하면 된다. <br>
 
   규제를 하는 경우 규제의 양은 하이퍼파라미터가 결정한다. 이는 학습 알고리즘의 파라미터이기 때문에 학습 알고리즘으로부터 영향을 받지 않고 훈련전에 미리 지정되며 훈련동안 계속 상수로 남게 된다. 이때 규제가 너무 큰 경우 과대적합은 피할지언정 좋은 모델이 안나오고 규제가 작으면 과대적합할 수도 있으므로 잘 선택해야한다.
 
 - 훈련데이터의 과소적합: 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지못하는 경우 이 경우는 위와 반대로 파라미터가 더 많은 모델을 쓰거나, 알고리즘에 특성을 좋은것으로 바꾸거나 모델의 규제를 줄이는 방법을 사용한다.

### 테스트와 검증 
테스트 세트를 이용하여 검증을 하는 경우 실제 서비스 사용시 오차율이 큰 경우가 있다. 이는 훈련을 하면서 테스트세트에 최적화된 모델이 만들어 졌기 때문이다. 이러한 문제를 막기 위해서 대표적으로 홀드아웃 검증이라는 것을 사용할 수 있다.

 - 홀드아웃 검증 : 훈련 세트의 일부를 검증 세트로 떼어내어 여러 후보 모델을 평가하고 가장 좋은 하나를 택하는 방법으로, 이 과정이 끝나면 다시 검증 세트를 포함시켜 전체 훈련 세트에서 다시 훈련하여 최종 모델을 만들고 이를 테스트 세트에 평가하여 일반화 오차를 측정하는 것이다. <br>
 
   다만 검증세트를 너무 작게 고를경우 모델의 평가가 부정확해지고 검증세트가 너무 클경우 남은 훈련세트가 너무 작아져서 잘못된 모델이 만들어질 경우가 있다. 이를 해결하기 위해서 교차검증을 사용하는데, 이는 작은 검증세트를 여러 개 사용해여 반복적으로 교차 검증을 수행해 검증세트마다 나머지 데이터에서 훈련한 모델을 해당 검증세트에서 평가하는 것이다.<br>
   이에 단점은 검증세트를 훈련세트를 n등분한다했을 때 n배의 시간이 걸려 세트수가 많을수록 걸리는 시간이 배로 늘어나는것이다.

